{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c660246-4063-4ff9-bc56-a0bc5d4f93d2",
   "metadata": {},
   "source": [
    "## 1. Neural Network Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ee602-585a-4623-b761-15329c65906e",
   "metadata": {},
   "source": [
    "<img src=\"img/pic49.png\" width=400 height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5d747-7e6e-4070-abd7-5bdfb924ea8f",
   "metadata": {},
   "source": [
    "#### 1.1 The forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d4a232-58ad-470b-a053-5c8eaf9cdcec",
   "metadata": {},
   "source": [
    "<img src=\"img/pic42.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a2d26-6899-4776-bd1d-8c8b544cb54c",
   "metadata": {},
   "source": [
    "#### 2.1 The backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b303bec-8d9e-4002-80c6-c90b17f953e5",
   "metadata": {},
   "source": [
    "<img src=\"img/pic43.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28f39ac-9222-4705-8610-e3ff5e364166",
   "metadata": {},
   "source": [
    "#### Output layer derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4a500-7b97-4635-b796-4e3a6c425690",
   "metadata": {},
   "source": [
    "<img src=\"img/pic44.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c804a9-8069-4a65-9202-47efe20c0068",
   "metadata": {},
   "source": [
    "<img src=\"img/pic45.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed48ce4-c8bc-4959-8d6e-b6e1fbefcfd3",
   "metadata": {},
   "source": [
    "#### Hidden layer derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea7b9e4-171f-42d8-b4f6-6c52edc36caa",
   "metadata": {},
   "source": [
    "<img src=\"img/pic46.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfffeb2-80a8-4dfc-a578-9ffd871439a9",
   "metadata": {},
   "source": [
    "<img src=\"img/pic48.png\" width=300 height=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2bab0-8906-4449-8d45-c7130170db9d",
   "metadata": {},
   "source": [
    "<img src=\"img/pic47.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96bd04-9c89-4e45-8dea-9e636c062052",
   "metadata": {},
   "source": [
    "**Modern deep learning frameworks such as PyTorch and TensorFlow calculate the derivatives automatically, given the model specification. This is known as algorithmic differentiation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936ba0e-90d2-4a93-b190-448d63867e8a",
   "metadata": {},
   "source": [
    "_________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa486e4f-45a6-43e9-b625-3368512bdb75",
   "metadata": {},
   "source": [
    "### 2. Measuring performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a230c30-8242-4acb-8481-a510c77bd803",
   "metadata": {},
   "source": [
    "- With suﬀicient capacity (i.e., number of hidden units), a neural network model will often perform perfectly on the training data. \n",
    "\n",
    "- However, this does not necessarily mean it will generalize well to new test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ebe7d-d467-485f-a5b5-76b0d3f7c5bf",
   "metadata": {},
   "source": [
    "**Generalization** capability could be related to \n",
    "- (i) the inherent uncertainty in the task,\n",
    "- (ii) the amount of training data, and\n",
    "- (iii) the choice of model (hyperparameter search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0b7a1-2c70-40e0-8185-679d29d5f495",
   "metadata": {},
   "source": [
    "#### Choosing hyperparameters\n",
    "\n",
    "- It is typical to divide the data into three parts:\n",
    "    - **training data** (to learn the model parameters)\n",
    "    - **validation data** (to choose the hyperparameters)\n",
    "    - **test data** (to estimate the final performance)\n",
    "<br>\n",
    "\n",
    "- However, this division may cause problems where the total number of data examples is limited; if the number of training examples is comparable to the model capacity, then the variance will be large.\n",
    "\n",
    "- One way to mitigate this problem is to use k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c01eb-c96b-45ca-a9df-8c10c26b805d",
   "metadata": {},
   "source": [
    "<img src=\"img/grid_search_cross_validation.png\" width=400 height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae68d24-c8f0-4a56-9f77-d94b87ecc5af",
   "metadata": {},
   "source": [
    "See [Model selection and evaluation](https://scikit-learn.org/stable/model_selection.html) on scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0288750-1d32-4770-a290-1f97d708f709",
   "metadata": {},
   "source": [
    "<img src=\"img/pic50.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98310850-685d-4680-9eb4-d78ef6057b1e",
   "metadata": {},
   "source": [
    "#### Why could the model fail to generalize?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a080cfa-81d8-47a8-9f93-aa29be55556d",
   "metadata": {},
   "source": [
    "There are three possible sources of error, which are known as **noise, bias, and variance** respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dde5aaa-738b-47eb-9684-3c69f41a9552",
   "metadata": {},
   "source": [
    "<img src=\"img/pic51.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77569a7a-2699-457a-a9cc-7b9aab2a45d2",
   "metadata": {},
   "source": [
    "#### Noise\n",
    "- The data generation process includes the addition of noise, so there are multiple possible valid outputs $y$ for each input $x$\n",
    "- So even if the model exactly replicates the true underlying function (black line), the noise in the test data (gray points) means that some error will remain\n",
    "- **Can we reduce noise?** The noise component is insurmountable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6add53d-7b1a-4217-9c98-7ccd885115ad",
   "metadata": {},
   "source": [
    "#### Bias \n",
    "- The model is not flexible enough to fit the true function perfectly\n",
    "- **We reduce bias** by making the model more flexible (increasing the model capacity). In NN, adding more hidden units and/or hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b438f8fc-3d8d-43ca-89b3-03b618850f6d",
   "metadata": {},
   "source": [
    "#### Variance\n",
    "\n",
    "-  We have limited noisy training data (orange points). When we fit the model, we don’t recover the best possible function from panel\n",
    "\n",
    "-  Variance is the difference between the true underlying function and the learned function.\n",
    "  \n",
    ">> In practice, there might also be additional variance due to the stochastic learning algorithm, which does not necessarily converge to the same solution each time.\n",
    "\n",
    "- **We can reduce variance** by increasing the quantity of training data to average out the noisy samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb3ef16-2c81-4937-9420-189009450e35",
   "metadata": {},
   "source": [
    "#### Bias-variance trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7417838-be1d-4c34-a56c-9d64510e61ae",
   "metadata": {},
   "source": [
    "- For a fixed-size training dataset, the variance term typically increases as the model capacity increases.\n",
    "- Consequently, increasing the model capacity does not necessarily reduce the test error. This is known as the bias-variance trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4ea55a-a6e0-4fe9-9210-96ccaf8a6f3b",
   "metadata": {},
   "source": [
    "<img src=\"img/pic52.png\" width=500 height=500 />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
